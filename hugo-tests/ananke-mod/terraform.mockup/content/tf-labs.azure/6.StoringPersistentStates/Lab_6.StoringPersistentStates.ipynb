{"cells": [{"cell_type": "code", "execution_count": 2, "id": "60e58e4e", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["2023-Jan-09:[TF-1.3.7] Lab updated on node tf[terraform 1.3.7]\n"]}, {"ename": "", "evalue": "1", "output_type": "error", "traceback": []}], "source": [""]}, {"cell_type": "markdown", "id": "broadband-radar", "metadata": {}, "source": ["\n\n<img align=\"left\" src=\"../images/ThinBlueBar.png\" /><br/>\n\n# Working with Remote State\n", "\n", "\n\n<img align=\"left\" src=\"../images/ThinBlueBar.png\" width=\"400\" /><br/>\n\n## Background:  \n", "Here, we learn how to create S3 buckets for persistent storage and use DynamoDB to store our states in tables.  We do this so that we can store our tfstate files remotely, and securely and allow versioning control so that recovery and rollbacks can be achieved as required.  \n", "\n", "See http://aws-cloud.guru/terraform-aws-backend-for-remote-state-files-with-s3-and-dynamodb/ for more details.\n", "\n", "\n\n<img align=\"left\" src=\"../images/ThinBlueBar.png\" width=\"400\" /><br/>\n\n## Tasks:\n", "\n", "### 1. Make a directory called \u2018lab6\u2019 underneath the labs directory.\n", "\n", "### 2. Change into the directory.\n", "\n", "### 3. Create a file main.tf\n", "\n", "In that file define \"*aws_s3_bucket*\" and \"*aws_dynamodb_table*\" resources as below"]}, {"cell_type": "code", "execution_count": 6, "id": "academic-radical", "metadata": {"attributes": {"classes": ["tf"], "id": ""}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "provider \"aws\" {\n", "  region = var.region\n", "}\n", "\n", "resource \"aws_s3_bucket\" \"remote_state\" {\n", "  bucket = var.unique_bucket_name\n", "\n", "  # Removed in hashicorp/aws version 4.0.0: now use aws_s3_bucket_acl if needed:\n", "  # acl    = \"private\"\n", "\n", "  # Removed in hashicorp/aws version 4.0.0: now use aws_s3_bucket_versioning if needed:\n", "  # versioning {    enabled = true  }\n", "\n", "  lifecycle { prevent_destroy = false }\n", "  \n", "  tags = {\n", "      LabName = \"6.StoringPersistentStates\"\n", "  }\n", "\n", "  # All objects to be deleted from bucket to allow bucket deletion without error\n", "  force_destroy = true\n", "}\n", "\n", "resource \"aws_dynamodb_table\" \"terraform_locks\" {\n", "  name           = var.dynamodb_lock_table_name\n", "  read_capacity  = 1\n", "  write_capacity = 1\n", "  hash_key       = \"LockID\" \n", "\n", "  tags = {\n", "      LabName = \"6.StoringPersistentStates\"\n", "  }\n", "\n", "  attribute {\n", "    name = \"LockID\"\n", "    type = \"S\"\n", "  }\n", "}\n", "\n"]}], "source": ["cat main.tf"]}, {"cell_type": "code", "execution_count": 7, "id": "eb994ad0", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["variable region {\n", "    default = \"us-west-1\"\n", "}\n", "\n", "variable unique_bucket_name {\n", "    # e.g. default = \"20201020-student21\"\n", "    default = \"20230109-mjbrightc\"\n", "}\n", "\n", "variable dynamodb_lock_table_name {\n", "    default = \"dynamodb-lock\"\n", "}\n"]}], "source": ["cat vars.tf"]}, {"cell_type": "markdown", "id": "formed-fifteen", "metadata": {}, "source": ["**Note**: The table **must** have a primary key '*hash_key*' named '*LockID*'. If not present, locking will be disabled\n", "\n", "Here we tie the state file to the dynamodb instance by creating a table in the database that uses the .tfstate file as its data source.\n", "\n", "### 4. Create a file vars.tf - enter *your* unique values here\n", "\n", "**Note**: I suggest you name the bucket including your student name e.g. 20230110-student21"]}, {"cell_type": "markdown", "id": "provincial-insert", "metadata": {"attributes": {"classes": ["tf"], "id": ""}}, "source": ["Your vars.tf should look something like:\n", "\n", "```\n", "variable region {\n", "    default = \"us-west-1\"\n", "}\n", "\n", "variable unique_bucket_name {\n", "    # e.g. default = \"20230110-student21\"\n", "    default = \"<your-unique-name-here>\"\n", "}\n", "\n", "variable dynamodb_lock_table_name {\n", "    default = \"dynamodb-lock\"\n", "}\n", "```\n"]}, {"cell_type": "markdown", "id": "prospective-thirty", "metadata": {}, "source": ["### 5. Create the S3 and DynamoDB Resources\n", "\n", "We will now perform a terraform init and a terraform apply\n", "\n", "**Note**: We do this before creating the backend definition file\n", "\n", "**Note**: Alternatively we could have manually created the bucket via the AWS Console or using the cli (```aws s3 mb s3://20230110-student21``` ) **or** Created the bucket from a separate Terraform environment\n", " \n", "**Note**: Alternatively, it is also possible to pass the variables directly to the init command as described here\n", "https://www.terraform.io/docs/commands/init.html#backend-initialization\n", "\n", "#### Initializing the workspace - *without the backend*\n", "\n", "We first initalize the workspace."]}, {"cell_type": "code", "execution_count": 8, "id": "technical-ivory", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "Initializing the backend...\n", "\n", "Initializing provider plugins...\n", "- Finding latest version of hashicorp/aws...\n", "- Installing hashicorp/aws v4.49.0...\n", "- Installed hashicorp/aws v4.49.0 (signed by HashiCorp)\n", "\n", "Terraform has created a lock file .terraform.lock.hcl to record the provider\n", "selections it made above. Include this file in your version control repository\n", "so that Terraform can guarantee to make the same selections by default when\n", "you run \"terraform init\" in the future.\n", "\n", "Terraform has been successfully initialized!\n", "\n", "You may now begin working with Terraform. Try running \"terraform plan\" to see\n", "any changes that are required for your infrastructure. All Terraform commands\n", "should now work.\n", "\n", "If you ever set or change modules or backend configuration for Terraform,\n", "rerun this command to reinitialize your working directory. If you forget, other\n", "commands will detect it and remind you to do so if necessary.\n"]}], "source": ["terraform init"]}, {"cell_type": "markdown", "id": "willing-crazy", "metadata": {}, "source": ["In case of errors you may wish to re-run init with trace logging:"]}, {"cell_type": "code", "execution_count": 9, "id": "compatible-literacy", "metadata": {"attributes": {"classes": ["sh"], "id": ""}, "scrolled": false}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["2023-01-09T18:44:31.906Z [INFO]  Terraform version: 1.3.7\n", "2023-01-09T18:44:31.906Z [DEBUG] using github.com/hashicorp/go-tfe v1.9.0\n", "2023-01-09T18:44:31.906Z [DEBUG] using github.com/hashicorp/hcl/v2 v2.15.0\n", "2023-01-09T18:44:31.906Z [DEBUG] using github.com/hashicorp/terraform-config-inspect v0.0.0-20210209133302-4fd17a0faac2\n", "2023-01-09T18:44:31.906Z [DEBUG] using github.com/hashicorp/terraform-svchost v0.0.0-20200729002733-f050f53b9734\n", "2023-01-09T18:44:31.906Z [DEBUG] using github.com/zclconf/go-cty v1.12.1\n", "2023-01-09T18:44:31.906Z [INFO]  Go runtime version: go1.19.4\n", "2023-01-09T18:44:31.906Z [INFO]  CLI args: []string{\"terraform\", \"init\"}\n", "2023-01-09T18:44:31.906Z [TRACE] Stdout is not a terminal\n", "2023-01-09T18:44:31.906Z [TRACE] Stderr is a terminal of width 80\n", "2023-01-09T18:44:31.906Z [TRACE] Stdin is a terminal\n", "2023-01-09T18:44:31.906Z [DEBUG] Attempting to open CLI config file: /home/student/.terraformrc\n", "2023-01-09T18:44:31.906Z [DEBUG] File doesn't exist, but doesn't need to. Ignoring.\n", "2023-01-09T18:44:31.906Z [DEBUG] ignoring non-existing provider search directory terraform.d/plugins\n", "2023-01-09T18:44:31.906Z [DEBUG] ignoring non-existing provider search directory /home/student/.terraform.d/plugins\n", "2023-01-09T18:44:31.906Z [DEBUG] ignoring non-existing provider search directory /home/student/.local/share/terraform/plugins\n", "2023-01-09T18:44:31.906Z [DEBUG] ignoring non-existing provider search directory /usr/local/share/terraform/plugins\n", "2023-01-09T18:44:31.906Z [DEBUG] ignoring non-existing provider search directory /usr/share/terraform/plugins\n", "2023-01-09T18:44:31.906Z [DEBUG] ignoring non-existing provider search directory /var/lib/snapd/desktop/terraform/plugins\n", "2023-01-09T18:44:31.907Z [INFO]  CLI command args: []string{\"init\"}\n", "\n", "Initializing the backend...\n", "2023-01-09T18:44:31.917Z [TRACE] Meta.Backend: no config given or present on disk, so returning nil config\n", "2023-01-09T18:44:31.917Z [TRACE] Meta.Backend: backend has not previously been initialized in this working directory\n", "2023-01-09T18:44:31.917Z [DEBUG] New state was assigned lineage \"39053fe4-4d44-d3b7-b4f4-e289ad333620\"\n", "2023-01-09T18:44:31.917Z [TRACE] Meta.Backend: using default local state only (no backend configuration, and no existing initialized backend)\n", "2023-01-09T18:44:31.917Z [TRACE] Meta.Backend: instantiated backend of type <nil>\n", "2023-01-09T18:44:31.919Z [TRACE] providercache.fillMetaCache: scanning directory /home/student/dot.terraform/providers\n", "2023-01-09T18:44:31.919Z [TRACE] getproviders.SearchLocalDirectory: found registry.terraform.io/hashicorp/aws v4.49.0 for linux_amd64 at /home/student/dot.terraform/providers/registry.terraform.io/hashicorp/aws/4.49.0/linux_amd64\n", "2023-01-09T18:44:31.919Z [TRACE] getproviders.SearchLocalDirectory: found registry.terraform.io/hashicorp/kubernetes v2.16.1 for linux_amd64 at /home/student/dot.terraform/providers/registry.terraform.io/hashicorp/kubernetes/2.16.1/linux_amd64\n", "2023-01-09T18:44:31.919Z [TRACE] getproviders.SearchLocalDirectory: found registry.terraform.io/hashicorp/local v2.2.3 for linux_amd64 at /home/student/dot.terraform/providers/registry.terraform.io/hashicorp/local/2.2.3/linux_amd64\n", "2023-01-09T18:44:31.919Z [TRACE] getproviders.SearchLocalDirectory: found registry.terraform.io/hashicorp/tls v4.0.4 for linux_amd64 at /home/student/dot.terraform/providers/registry.terraform.io/hashicorp/tls/4.0.4/linux_amd64\n", "2023-01-09T18:44:31.919Z [TRACE] getproviders.SearchLocalDirectory: found registry.terraform.io/kreuzwerker/docker v2.25.0 for linux_amd64 at /home/student/dot.terraform/providers/registry.terraform.io/kreuzwerker/docker/2.25.0/linux_amd64\n", "2023-01-09T18:44:31.919Z [TRACE] providercache.fillMetaCache: including /home/student/dot.terraform/providers/registry.terraform.io/hashicorp/tls/4.0.4/linux_amd64 as a candidate package for registry.terraform.io/hashicorp/tls 4.0.4\n", "2023-01-09T18:44:31.919Z [TRACE] providercache.fillMetaCache: including /home/student/dot.terraform/providers/registry.terraform.io/kreuzwerker/docker/2.25.0/linux_amd64 as a candidate package for registry.terraform.io/kreuzwerker/docker 2.25.0\n", "2023-01-09T18:44:31.919Z [TRACE] providercache.fillMetaCache: including /home/student/dot.terraform/providers/registry.terraform.io/hashicorp/aws/4.49.0/linux_amd64 as a candidate package for registry.terraform.io/hashicorp/aws 4.49.0\n", "2023-01-09T18:44:31.919Z [TRACE] providercache.fillMetaCache: including /home/student/dot.terraform/providers/registry.terraform.io/hashicorp/kubernetes/2.16.1/linux_amd64 as a candidate package for registry.terraform.io/hashicorp/kubernetes 2.16.1\n", "2023-01-09T18:44:31.919Z [TRACE] providercache.fillMetaCache: including /home/student/dot.terraform/providers/registry.terraform.io/hashicorp/local/2.2.3/linux_amd64 as a candidate package for registry.terraform.io/hashicorp/local 2.2.3\n", "2023-01-09T18:44:32.825Z [DEBUG] checking for provisioner in \".\"\n", "2023-01-09T18:44:32.825Z [DEBUG] checking for provisioner in \"/home/student/bin\"\n", "2023-01-09T18:44:32.825Z [TRACE] Meta.Backend: backend <nil> does not support operations, so wrapping it in a local backend\n", "2023-01-09T18:44:32.825Z [TRACE] backend/local: state manager for workspace \"default\" will:\n", " - read initial snapshot from terraform.tfstate\n", " - write new snapshots to terraform.tfstate\n", " - create any backup at terraform.tfstate.backup\n", "2023-01-09T18:44:32.825Z [TRACE] statemgr.Filesystem: reading initial snapshot from terraform.tfstate\n", "2023-01-09T18:44:32.825Z [TRACE] statemgr.Filesystem: snapshot file has nil snapshot, but that's okay\n", "2023-01-09T18:44:32.825Z [TRACE] statemgr.Filesystem: read nil snapshot\n", "\n", "Initializing provider plugins...\n", "- Reusing previous version of hashicorp/aws from the dependency lock file\n", "2023-01-09T18:44:32.825Z [DEBUG] Service discovery for registry.terraform.io at https://registry.terraform.io/.well-known/terraform.json\n", "2023-01-09T18:44:32.826Z [TRACE] HTTP client GET request to https://registry.terraform.io/.well-known/terraform.json\n", "2023-01-09T18:44:32.908Z [DEBUG] GET https://registry.terraform.io/v1/providers/hashicorp/aws/versions\n", "2023-01-09T18:44:32.908Z [TRACE] HTTP client GET request to https://registry.terraform.io/v1/providers/hashicorp/aws/versions\n", "2023-01-09T18:44:32.980Z [TRACE] providercache.fillMetaCache: scanning directory /home/student/dot.terraform/providers\n", "2023-01-09T18:44:32.980Z [TRACE] getproviders.SearchLocalDirectory: found registry.terraform.io/hashicorp/aws v4.49.0 for linux_amd64 at /home/student/dot.terraform/providers/registry.terraform.io/hashicorp/aws/4.49.0/linux_amd64\n", "2023-01-09T18:44:32.982Z [TRACE] getproviders.SearchLocalDirectory: found registry.terraform.io/hashicorp/kubernetes v2.16.1 for linux_amd64 at /home/student/dot.terraform/providers/registry.terraform.io/hashicorp/kubernetes/2.16.1/linux_amd64\n", "2023-01-09T18:44:32.983Z [TRACE] getproviders.SearchLocalDirectory: found registry.terraform.io/hashicorp/local v2.2.3 for linux_amd64 at /home/student/dot.terraform/providers/registry.terraform.io/hashicorp/local/2.2.3/linux_amd64\n", "2023-01-09T18:44:32.983Z [TRACE] getproviders.SearchLocalDirectory: found registry.terraform.io/hashicorp/tls v4.0.4 for linux_amd64 at /home/student/dot.terraform/providers/registry.terraform.io/hashicorp/tls/4.0.4/linux_amd64\n", "2023-01-09T18:44:32.983Z [TRACE] getproviders.SearchLocalDirectory: found registry.terraform.io/kreuzwerker/docker v2.25.0 for linux_amd64 at /home/student/dot.terraform/providers/registry.terraform.io/kreuzwerker/docker/2.25.0/linux_amd64\n", "2023-01-09T18:44:32.983Z [TRACE] providercache.fillMetaCache: including /home/student/dot.terraform/providers/registry.terraform.io/hashicorp/local/2.2.3/linux_amd64 as a candidate package for registry.terraform.io/hashicorp/local 2.2.3\n", "2023-01-09T18:44:32.983Z [TRACE] providercache.fillMetaCache: including /home/student/dot.terraform/providers/registry.terraform.io/hashicorp/tls/4.0.4/linux_amd64 as a candidate package for registry.terraform.io/hashicorp/tls 4.0.4\n", "2023-01-09T18:44:32.983Z [TRACE] providercache.fillMetaCache: including /home/student/dot.terraform/providers/registry.terraform.io/kreuzwerker/docker/2.25.0/linux_amd64 as a candidate package for registry.terraform.io/kreuzwerker/docker 2.25.0\n"]}, {"name": "stdout", "output_type": "stream", "text": ["2023-01-09T18:44:32.983Z [TRACE] providercache.fillMetaCache: including /home/student/dot.terraform/providers/registry.terraform.io/hashicorp/aws/4.49.0/linux_amd64 as a candidate package for registry.terraform.io/hashicorp/aws 4.49.0\n", "2023-01-09T18:44:32.983Z [TRACE] providercache.fillMetaCache: including /home/student/dot.terraform/providers/registry.terraform.io/hashicorp/kubernetes/2.16.1/linux_amd64 as a candidate package for registry.terraform.io/hashicorp/kubernetes 2.16.1\n", "- Using previously-installed hashicorp/aws v4.49.0\n", "\n", "Terraform has been successfully initialized!\n", "\n", "You may now begin working with Terraform. Try running \"terraform plan\" to see\n", "any changes that are required for your infrastructure. All Terraform commands\n", "should now work.\n", "\n", "If you ever set or change modules or backend configuration for Terraform,\n", "rerun this command to reinitialize your working directory. If you forget, other\n", "commands will detect it and remind you to do so if necessary.\n"]}], "source": ["TF_LOG=TRACE terraform init | tee terraform.init.log.1"]}, {"cell_type": "markdown", "id": "lucky-mozambique", "metadata": {}, "source": ["#### Creating the resources\n", "\n", "We can now create the resources\n", "\n", "**Note**: At this stage the file *backend.tf* must not be present"]}, {"cell_type": "code", "execution_count": 10, "id": "nervous-juvenile", "metadata": {"scrolled": false}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "Terraform used the selected providers to generate the following execution plan.\n", "Resource actions are indicated with the following symbols:\n", "  + create\n", "\n", "Terraform will perform the following actions:\n", "\n", "  # aws_dynamodb_table.terraform_locks will be created\n", "  + resource \"aws_dynamodb_table\" \"terraform_locks\" {\n", "      + arn              = (known after apply)\n", "      + billing_mode     = \"PROVISIONED\"\n", "      + hash_key         = \"LockID\"\n", "      + id               = (known after apply)\n", "      + name             = \"dynamodb-lock\"\n", "      + read_capacity    = 1\n", "      + stream_arn       = (known after apply)\n", "      + stream_label     = (known after apply)\n", "      + stream_view_type = (known after apply)\n", "      + tags             = {\n", "          + \"LabName\" = \"6.StoringPersistentStates\"\n", "        }\n", "      + tags_all         = {\n", "          + \"LabName\" = \"6.StoringPersistentStates\"\n", "        }\n", "      + write_capacity   = 1\n", "\n", "      + attribute {\n", "          + name = \"LockID\"\n", "          + type = \"S\"\n", "        }\n", "\n", "      + point_in_time_recovery {\n", "          + enabled = (known after apply)\n", "        }\n", "\n", "      + server_side_encryption {\n", "          + enabled     = (known after apply)\n", "          + kms_key_arn = (known after apply)\n", "        }\n", "\n", "      + ttl {\n", "          + attribute_name = (known after apply)\n", "          + enabled        = (known after apply)\n", "        }\n", "    }\n", "\n", "  # aws_s3_bucket.remote_state will be created\n", "  + resource \"aws_s3_bucket\" \"remote_state\" {\n", "      + acceleration_status         = (known after apply)\n", "      + acl                         = (known after apply)\n", "      + arn                         = (known after apply)\n", "      + bucket                      = \"20230109-mjbrightc\"\n", "      + bucket_domain_name          = (known after apply)\n", "      + bucket_regional_domain_name = (known after apply)\n", "      + force_destroy               = true\n", "      + hosted_zone_id              = (known after apply)\n", "      + id                          = (known after apply)\n", "      + object_lock_enabled         = (known after apply)\n", "      + policy                      = (known after apply)\n", "      + region                      = (known after apply)\n", "      + request_payer               = (known after apply)\n", "      + tags                        = {\n", "          + \"LabName\" = \"6.StoringPersistentStates\"\n", "        }\n", "      + tags_all                    = {\n", "          + \"LabName\" = \"6.StoringPersistentStates\"\n", "        }\n", "      + website_domain              = (known after apply)\n", "      + website_endpoint            = (known after apply)\n", "\n", "      + cors_rule {\n", "          + allowed_headers = (known after apply)\n", "          + allowed_methods = (known after apply)\n", "          + allowed_origins = (known after apply)\n", "          + expose_headers  = (known after apply)\n", "          + max_age_seconds = (known after apply)\n", "        }\n", "\n", "      + grant {\n", "          + id          = (known after apply)\n", "          + permissions = (known after apply)\n", "          + type        = (known after apply)\n", "          + uri         = (known after apply)\n", "        }\n", "\n", "      + lifecycle_rule {\n", "          + abort_incomplete_multipart_upload_days = (known after apply)\n", "          + enabled                                = (known after apply)\n", "          + id                                     = (known after apply)\n", "          + prefix                                 = (known after apply)\n", "          + tags                                   = (known after apply)\n", "\n", "          + expiration {\n", "              + date                         = (known after apply)\n", "              + days                         = (known after apply)\n", "              + expired_object_delete_marker = (known after apply)\n", "            }\n", "\n", "          + noncurrent_version_expiration {\n", "              + days = (known after apply)\n", "            }\n", "\n", "          + noncurrent_version_transition {\n", "              + days          = (known after apply)\n", "              + storage_class = (known after apply)\n", "            }\n", "\n", "          + transition {\n", "              + date          = (known after apply)\n", "              + days          = (known after apply)\n", "              + storage_class = (known after apply)\n", "            }\n", "        }\n", "\n", "      + logging {\n", "          + target_bucket = (known after apply)\n", "          + target_prefix = (known after apply)\n", "        }\n", "\n", "      + object_lock_configuration {\n", "          + object_lock_enabled = (known after apply)\n", "\n", "          + rule {\n", "              + default_retention {\n", "                  + days  = (known after apply)\n", "                  + mode  = (known after apply)\n", "                  + years = (known after apply)\n", "                }\n", "            }\n", "        }\n", "\n", "      + replication_configuration {\n", "          + role = (known after apply)\n", "\n", "          + rules {\n", "              + delete_marker_replication_status = (known after apply)\n", "              + id                               = (known after apply)\n", "              + prefix                           = (known after apply)\n", "              + priority                         = (known after apply)\n", "              + status                           = (known after apply)\n", "\n", "              + destination {\n", "                  + account_id         = (known after apply)\n", "                  + bucket             = (known after apply)\n", "                  + replica_kms_key_id = (known after apply)\n", "                  + storage_class      = (known after apply)\n", "\n", "                  + access_control_translation {\n", "                      + owner = (known after apply)\n", "                    }\n", "\n", "                  + metrics {\n", "                      + minutes = (known after apply)\n", "                      + status  = (known after apply)\n", "                    }\n"]}, {"name": "stdout", "output_type": "stream", "text": ["\n", "                  + replication_time {\n", "                      + minutes = (known after apply)\n", "                      + status  = (known after apply)\n", "                    }\n", "                }\n", "\n", "              + filter {\n", "                  + prefix = (known after apply)\n", "                  + tags   = (known after apply)\n", "                }\n", "\n", "              + source_selection_criteria {\n", "                  + sse_kms_encrypted_objects {\n", "                      + enabled = (known after apply)\n", "                    }\n", "                }\n", "            }\n", "        }\n", "\n", "      + server_side_encryption_configuration {\n", "          + rule {\n", "              + bucket_key_enabled = (known after apply)\n", "\n", "              + apply_server_side_encryption_by_default {\n", "                  + kms_master_key_id = (known after apply)\n", "                  + sse_algorithm     = (known after apply)\n", "                }\n", "            }\n", "        }\n", "\n", "      + versioning {\n", "          + enabled    = (known after apply)\n", "          + mfa_delete = (known after apply)\n", "        }\n", "\n", "      + website {\n", "          + error_document           = (known after apply)\n", "          + index_document           = (known after apply)\n", "          + redirect_all_requests_to = (known after apply)\n", "          + routing_rules            = (known after apply)\n", "        }\n", "    }\n", "\n", "Plan: 2 to add, 0 to change, 0 to destroy.\n", "aws_dynamodb_table.terraform_locks: Creating...\n", "aws_s3_bucket.remote_state: Creating...\n", "aws_s3_bucket.remote_state: Creation complete after 5s [id=20230109-mjbrightc]\n", "aws_dynamodb_table.terraform_locks: Creation complete after 8s [id=dynamodb-lock]\n", "\n", "Apply complete! Resources: 2 added, 0 changed, 0 destroyed.\n", "\n"]}], "source": ["terraform apply "]}, {"cell_type": "markdown", "id": "verified-tamil", "metadata": {}, "source": ["#### If you get the 'Table already exists' error\n", "\n", "If you get the following error:\n", "\n", "```\n", "aws_s3_bucket.remote_state: Creating...\n", "aws_dynamodb_table.terraform_locks: Creating...\n", "aws_s3_bucket.remote_state: Still creating... [10s elapsed]\n", "aws_s3_bucket.remote_state: Creation complete after 13s [id=20210203-mjbrightc]\n", "\n", "Error: error creating DynamoDB Table: ResourceInUseException: Table already exists: dynamodb-lock\n", "```\n", "\n", "(**in this lab environment, not in production**) you will first need to delete the existing table using:\n", "\n", "```\n", "aws dynamodb delete-table --table-name dynamodb-lock\n", "```\n", "\n", "#### Verifying the resources\n", "\n", "Verify that your S3 bucket has been created using\n", "\n", "```\n", "    aws s3 ls \n", "    \n", "```"]}, {"cell_type": "markdown", "id": "quality-emergency", "metadata": {}, "source": ["Verify that your \"*dynamodb-lock*\" table has been created:"]}, {"cell_type": "code", "execution_count": 12, "id": "julian-contract", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{\n", "    \"TableNames\": [\n", "        \"dynamodb-lock\"\n", "    ]\n", "}\n"]}], "source": ["aws dynamodb list-tables"]}, {"cell_type": "markdown", "id": "provincial-vitamin", "metadata": {}, "source": ["### 6. Create a file backend.tf\n", "\n", "Now that we have created the necessary resources we will\n", "1. create a backend configuration\n", "2. re-perform the init\n", "3. verify the configuration\n", "\n", "We will create a file backend.tf\n", "\n", "This file will be used to make S3 - with DynamoDB locking - our remote_backend for storing state\n", "\n", "Unfortunately we cannot use variables in this file as they will not be interpreted by \"*terraform init*\".\n", "\n", "So you must manually enter the **same bucket name** in the content below:"]}, {"cell_type": "code", "execution_count": 14, "id": "coral-madonna", "metadata": {"attributes": {"classes": ["tf"], "id": ""}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "terraform {\n", "    backend \"s3\" {\n", "        #key = path/to/my/key\n", "        key = \"terraform.tfstate\"\n", "\n", "        #region = var.region\n", "        region = \"us-west-1\"\n", "\n", "        # ENTRY MUST BE UPDATED !!\n", "        # e.g. bucket = \"20201020-student21\"\n", "        bucket = \"20230109-mjbrightc\"\n", "\n", "        #dynamodb_table = var.dynamodb_lock_table_name\n", "        dynamodb_table = \"dynamodb-lock\"\n", "\n", "        encrypt = true # Optional, S3 Bucket Server Side Encryption\n", "     }\n", "}\n"]}], "source": [""]}, {"cell_type": "markdown", "id": "structural-extraction", "metadata": {}, "source": ["### 7. Initialize, preview and apply the complete configuration\n", "\n", "### 7.1 Init"]}, {"cell_type": "code", "execution_count": 15, "id": "written-ladder", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "Initializing the backend...\n", "Acquiring state lock. This may take a few moments...\n", "Do you want to copy existing state to the new backend?\n", "  Pre-existing state was found while migrating the previous \"local\" backend to the\n", "  newly configured \"s3\" backend. No existing state was found in the newly\n", "  configured \"s3\" backend. Do you want to copy this state to the new \"s3\"\n", "  backend? Enter \"yes\" to copy and \"no\" to start with an empty state.\n", "\n", "  Enter a value: \n", "Releasing state lock. This may take a few moments...\n", "\n", "Successfully configured the backend \"s3\"! Terraform will automatically\n", "use this backend unless the backend configuration changes.\n", "\n", "Initializing provider plugins...\n", "- Reusing previous version of hashicorp/aws from the dependency lock file\n", "- Using previously-installed hashicorp/aws v4.49.0\n", "\n", "Terraform has been successfully initialized!\n", "\n", "You may now begin working with Terraform. Try running \"terraform plan\" to see\n", "any changes that are required for your infrastructure. All Terraform commands\n", "should now work.\n", "\n", "If you ever set or change modules or backend configuration for Terraform,\n", "rerun this command to reinitialize your working directory. If you forget, other\n", "commands will detect it and remind you to do so if necessary.\n"]}], "source": [" terraform  init -migrate-state\n", "echo yes | EXEC terraform init --backend=true  -migrate-state #--lock=false "]}, {"cell_type": "markdown", "id": "composed-regular", "metadata": {}, "source": ["#### In case of errors\n", "\n", "In case of errors also use the TF_LOG trace option again:"]}, {"cell_type": "markdown", "id": "fd4f4b5f", "metadata": {"attributes": {"classes": ["sh"], "id": ""}}, "source": ["```TF_LOG=TRACE terraform init --backend=true -migrate-state |& tee terraform.init.log.2```"]}, {"cell_type": "markdown", "id": "primary-roulette", "metadata": {}, "source": ["You can use the following command to verify that your dynamoDB table is still present (as it should be !)"]}, {"cell_type": "code", "execution_count": 16, "id": "least-cloud", "metadata": {"attributes": {"classes": ["sh"], "id": ""}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{\n", "    \"TableNames\": [\n", "        \"dynamodb-lock\"\n", "    ]\n", "}\n"]}], "source": ["aws dynamodb list-tables"]}, {"cell_type": "markdown", "id": "fallen-chocolate", "metadata": {}, "source": ["### 7.2 Verifying the state\n", "\n", "If all went well you got no errors and you local terraform.tfstate file is now empty as state is written to the S3 bucket"]}, {"cell_type": "code", "execution_count": 17, "id": "pressed-premium", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["-rw-rw-r-- 1 student student    0 Jan  9 18:46 terraform.tfstate\n", "-rw-rw-r-- 1 student student 4260 Jan  9 18:46 terraform.tfstate.backup\n"]}], "source": ["ls -al terraform.tfstate*"]}, {"cell_type": "markdown", "id": "diagnostic-custom", "metadata": {}, "source": ["### 7.3 Viewing the state in the S3 bucket\n", "\n", "#### Accessing the state via the cli"]}, {"cell_type": "code", "execution_count": 18, "id": "incorporated-object", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["2023-01-09 18:46:39       4260 terraform.tfstate\n"]}], "source": ["aws s3 ls s3://$BUCKET"]}, {"cell_type": "markdown", "id": "lucky-england", "metadata": {}, "source": ["and you should see a terraform.tfstate file there\n", "\n", "You can obtain a local copy to look at the file as follows:"]}, {"cell_type": "code", "execution_count": 19, "id": "bottom-printing", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["download: s3://20230109-mjbrightc/terraform.tfstate to ./terraform.tfstate.localcopy\n"]}], "source": ["aws s3 cp s3://$BUCKET/terraform.tfstate terraform.tfstate.localcopy"]}, {"cell_type": "markdown", "id": "surprising-pride", "metadata": {}, "source": ["#### Investigating the remote state\n", "\n", "Now using ```terraform state list``` and ```terraform state show RESOURCE``` we can investigate resources as before.\n", "\n", "You will notice that it is slower to respond as the state is obtained from our S3 bucket."]}, {"cell_type": "code", "execution_count": 20, "id": "precious-exchange", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["aws_dynamodb_table.terraform_locks\n", "aws_s3_bucket.remote_state\n"]}], "source": ["terraform state list "]}, {"cell_type": "code", "execution_count": 21, "id": "prescribed-investor", "metadata": {"scrolled": false}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["# aws_s3_bucket.remote_state:\n", "resource \"aws_s3_bucket\" \"remote_state\" {\n", "    arn                         = \"arn:aws:s3:::20230109-mjbrightc\"\n", "    bucket                      = \"20230109-mjbrightc\"\n", "    bucket_domain_name          = \"20230109-mjbrightc.s3.amazonaws.com\"\n", "    bucket_regional_domain_name = \"20230109-mjbrightc.s3.us-west-1.amazonaws.com\"\n", "    force_destroy               = true\n", "    hosted_zone_id              = \"Z2F56UZL2M1ACD\"\n", "    id                          = \"20230109-mjbrightc\"\n", "    object_lock_enabled         = false\n", "    region                      = \"us-west-1\"\n", "    request_payer               = \"BucketOwner\"\n", "    tags                        = {\n", "        \"LabName\" = \"6.StoringPersistentStates\"\n", "    }\n", "    tags_all                    = {\n", "        \"LabName\" = \"6.StoringPersistentStates\"\n", "    }\n", "\n", "    grant {\n", "        id          = \"968fa2d82a42737a0bed914a047f15154b89bf1bcc8c50a320a36a56c60f1ad1\"\n", "        permissions = [\n", "            \"FULL_CONTROL\",\n", "        ]\n", "        type        = \"CanonicalUser\"\n", "    }\n", "\n", "    versioning {\n", "        enabled    = false\n", "        mfa_delete = false\n", "    }\n", "}\n"]}], "source": ["terraform state show aws_s3_bucket.remote_state"]}, {"cell_type": "markdown", "id": "distinct-memorabilia", "metadata": {}, "source": ["#### Investigating the local copy\n", "\n", "We can also use ```terraform state list``` and ```terraform state show RESOURCE``` with the option ```-state=terraform.tfstate.localcopy ``` to investigate the state as stored in the local copy we just made."]}, {"cell_type": "code", "execution_count": 22, "id": "organic-darwin", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["aws_dynamodb_table.terraform_locks\n", "aws_s3_bucket.remote_state\n"]}], "source": ["terraform state list -state=terraform.tfstate.localcopy "]}, {"cell_type": "code", "execution_count": 23, "id": "thick-recognition", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["# aws_s3_bucket.remote_state:\n", "resource \"aws_s3_bucket\" \"remote_state\" {\n", "    arn                         = \"arn:aws:s3:::20230109-mjbrightc\"\n", "    bucket                      = \"20230109-mjbrightc\"\n", "    bucket_domain_name          = \"20230109-mjbrightc.s3.amazonaws.com\"\n", "    bucket_regional_domain_name = \"20230109-mjbrightc.s3.us-west-1.amazonaws.com\"\n", "    force_destroy               = true\n", "    hosted_zone_id              = \"Z2F56UZL2M1ACD\"\n", "    id                          = \"20230109-mjbrightc\"\n", "    object_lock_enabled         = false\n", "    region                      = \"us-west-1\"\n", "    request_payer               = \"BucketOwner\"\n", "    tags                        = {\n", "        \"LabName\" = \"6.StoringPersistentStates\"\n", "    }\n", "    tags_all                    = {\n", "        \"LabName\" = \"6.StoringPersistentStates\"\n", "    }\n", "\n", "    grant {\n", "        id          = \"968fa2d82a42737a0bed914a047f15154b89bf1bcc8c50a320a36a56c60f1ad1\"\n", "        permissions = [\n", "            \"FULL_CONTROL\",\n", "        ]\n", "        type        = \"CanonicalUser\"\n", "    }\n", "\n", "    versioning {\n", "        enabled    = false\n", "        mfa_delete = false\n", "    }\n", "}\n"]}], "source": ["terraform state show -state=terraform.tfstate.localcopy aws_s3_bucket.remote_state"]}, {"cell_type": "markdown", "id": "03e3c101", "metadata": {}, "source": ["### 8. Add a new resource\n", "\n", "Add a new resource - a 2nd bucket with a unique name\n", "\n", "Apply this config and see that the local state file doesn't change\n"]}, {"cell_type": "markdown", "id": "27ca9174", "metadata": {}, "source": ["The local terraform.tfstate file should remain empty despite the new resource created\n", "\n", "e.g."]}, {"cell_type": "code", "execution_count": 25, "id": "14dce28b", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["resource \"aws_s3_bucket\" \"test_bucket\" {\n", "  bucket = \"${var.unique_bucket_name}test\"\n", "\n", "  lifecycle { prevent_destroy = false }\n", "\n", "  tags = {\n", "      LabName = \"6.StoringPersistentStates\"\n", "  }\n", "\n", "  force_destroy = true \n", "}\n"]}], "source": ["cat test_bucket.tf"]}, {"cell_type": "code", "execution_count": 26, "id": "c9634c19", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Acquiring state lock. This may take a few moments...\n", "aws_s3_bucket.remote_state: Refreshing state... [id=20230109-mjbrightc]\n", "aws_dynamodb_table.terraform_locks: Refreshing state... [id=dynamodb-lock]\n", "\n", "Terraform used the selected providers to generate the following execution plan.\n", "Resource actions are indicated with the following symbols:\n", "  + create\n", "\n", "Terraform will perform the following actions:\n", "\n", "  # aws_s3_bucket.test_bucket will be created\n", "  + resource \"aws_s3_bucket\" \"test_bucket\" {\n", "      + acceleration_status         = (known after apply)\n", "      + acl                         = (known after apply)\n", "      + arn                         = (known after apply)\n", "      + bucket                      = \"20230109-mjbrightctest\"\n", "      + bucket_domain_name          = (known after apply)\n", "      + bucket_regional_domain_name = (known after apply)\n", "      + force_destroy               = true\n", "      + hosted_zone_id              = (known after apply)\n", "      + id                          = (known after apply)\n", "      + object_lock_enabled         = (known after apply)\n", "      + policy                      = (known after apply)\n", "      + region                      = (known after apply)\n", "      + request_payer               = (known after apply)\n", "      + tags                        = {\n", "          + \"LabName\" = \"6.StoringPersistentStates\"\n", "        }\n", "      + tags_all                    = {\n", "          + \"LabName\" = \"6.StoringPersistentStates\"\n", "        }\n", "      + website_domain              = (known after apply)\n", "      + website_endpoint            = (known after apply)\n", "\n", "      + cors_rule {\n", "          + allowed_headers = (known after apply)\n", "          + allowed_methods = (known after apply)\n", "          + allowed_origins = (known after apply)\n", "          + expose_headers  = (known after apply)\n", "          + max_age_seconds = (known after apply)\n", "        }\n", "\n", "      + grant {\n", "          + id          = (known after apply)\n", "          + permissions = (known after apply)\n", "          + type        = (known after apply)\n", "          + uri         = (known after apply)\n", "        }\n", "\n", "      + lifecycle_rule {\n", "          + abort_incomplete_multipart_upload_days = (known after apply)\n", "          + enabled                                = (known after apply)\n", "          + id                                     = (known after apply)\n", "          + prefix                                 = (known after apply)\n", "          + tags                                   = (known after apply)\n", "\n", "          + expiration {\n", "              + date                         = (known after apply)\n", "              + days                         = (known after apply)\n", "              + expired_object_delete_marker = (known after apply)\n", "            }\n", "\n", "          + noncurrent_version_expiration {\n", "              + days = (known after apply)\n", "            }\n", "\n", "          + noncurrent_version_transition {\n", "              + days          = (known after apply)\n", "              + storage_class = (known after apply)\n", "            }\n", "\n", "          + transition {\n", "              + date          = (known after apply)\n", "              + days          = (known after apply)\n", "              + storage_class = (known after apply)\n", "            }\n", "        }\n", "\n", "      + logging {\n", "          + target_bucket = (known after apply)\n", "          + target_prefix = (known after apply)\n", "        }\n", "\n", "      + object_lock_configuration {\n", "          + object_lock_enabled = (known after apply)\n", "\n", "          + rule {\n", "              + default_retention {\n", "                  + days  = (known after apply)\n", "                  + mode  = (known after apply)\n", "                  + years = (known after apply)\n", "                }\n", "            }\n", "        }\n", "\n", "      + replication_configuration {\n", "          + role = (known after apply)\n", "\n", "          + rules {\n", "              + delete_marker_replication_status = (known after apply)\n", "              + id                               = (known after apply)\n", "              + prefix                           = (known after apply)\n", "              + priority                         = (known after apply)\n", "              + status                           = (known after apply)\n", "\n", "              + destination {\n", "                  + account_id         = (known after apply)\n", "                  + bucket             = (known after apply)\n", "                  + replica_kms_key_id = (known after apply)\n", "                  + storage_class      = (known after apply)\n", "\n", "                  + access_control_translation {\n", "                      + owner = (known after apply)\n", "                    }\n", "\n", "                  + metrics {\n", "                      + minutes = (known after apply)\n", "                      + status  = (known after apply)\n", "                    }\n", "\n", "                  + replication_time {\n", "                      + minutes = (known after apply)\n", "                      + status  = (known after apply)\n", "                    }\n", "                }\n", "\n", "              + filter {\n", "                  + prefix = (known after apply)\n", "                  + tags   = (known after apply)\n", "                }\n", "\n", "              + source_selection_criteria {\n", "                  + sse_kms_encrypted_objects {\n", "                      + enabled = (known after apply)\n", "                    }\n", "                }\n", "            }\n", "        }\n", "\n", "      + server_side_encryption_configuration {\n", "          + rule {\n", "              + bucket_key_enabled = (known after apply)\n", "\n", "              + apply_server_side_encryption_by_default {\n", "                  + kms_master_key_id = (known after apply)\n", "                  + sse_algorithm     = (known after apply)\n", "                }\n", "            }\n", "        }\n", "\n", "      + versioning {\n", "          + enabled    = (known after apply)\n", "          + mfa_delete = (known after apply)\n", "        }\n", "\n", "      + website {\n", "          + error_document           = (known after apply)\n", "          + index_document           = (known after apply)\n"]}, {"name": "stdout", "output_type": "stream", "text": ["          + redirect_all_requests_to = (known after apply)\n", "          + routing_rules            = (known after apply)\n", "        }\n", "    }\n", "\n", "Plan: 1 to add, 0 to change, 0 to destroy.\n", "aws_s3_bucket.test_bucket: Creating...\n", "aws_s3_bucket.test_bucket: Creation complete after 4s [id=20230109-mjbrightctest]\n", "Releasing state lock. This may take a few moments...\n", "\n", "Apply complete! Resources: 1 added, 0 changed, 0 destroyed.\n", "\n", "aws_dynamodb_table.terraform_locks\n", "aws_s3_bucket.remote_state\n", "aws_s3_bucket.test_bucket\n", "-rw-rw-r-- 1 student student 0 Jan  9 18:46 terraform.tfstate\n"]}], "source": ["terraform apply -auto-approve\n", "\n", "terraform state list\n", "\n", "ls -al terraform.tfstate"]}, {"cell_type": "markdown", "id": "e6af955c", "metadata": {}, "source": ["#### Accessing the state via the AWS Console\n", "\n", "If you are performing this lab with your own AWS credentials, you can access the AWS Console to investigate the state their in the S3 bucket - see the below screen capture\n", "\n", "**Note:** the S3 bucket name is different here as this was a previous run with a differented dated bucket name.\n", "\n", "<!-- The S3 bucket:\n", "<img src=\"../images/S3_bucket_terraform_state.PNG\" /> -->\n", "\n", "#### The S3 bucket description:\n", "<img src=\"../images/S3_bucket_terraform_state_description.PNG\" />\n", "\n", "#### The terraform.tfstate file in the S3 bucket:\n", "<img src=\"../images/S3_bucket_terraform_state_content.PNG\" />"]}, {"cell_type": "markdown", "id": "combined-length", "metadata": {}, "source": ["### 9. The configuration when visualized should look like\n", "\n", "<div>\n", "    <object data=\"graph.svg\" type=\"image/svg+xml\">\n", "    </object>\n", "</div>\n", "\n", "<img src=\"graph.svg\" />\n", "\n", "#### Viewing your terraform.tfstate file as a graph\n", "\n", "**Note:** Remember that **once you have applied this config** can obtain a representation of this graph using the ```terraform graph``` command which you can copy into the web site https://dreampuf.github.io/GraphvizOnline/\n", "\n", "The output of ```terraform graph``` should look something like:\n", "```\n", "digraph {\n", "        compound = \"true\"\n", "        newrank = \"true\"\n", "        subgraph \"root\" {\n", "                \"[root] aws_subnet.vpc_subnets (expand)\" [label = \"aws_subnet.vpc_subnets\", shape = \"box\"]\n", "                \"[root] aws_vpc.main_vpc (expand)\" [label = \"aws_vpc.main_vpc\", shape = \"box\"]\n", "                \"[root] data.aws_availability_zones.aaz (expand)\" [label = \"data.aws_availability_zones.aaz\", shape = \"box\"]\n", "                \"[root] output.aazs\" [label = \"output.aazs\", shape = \"note\"]\n", "                \"[root] provider[\\\"registry.terraform.io/hashicorp/aws\\\"]\" [label = \"provider[\\\"registry.terraform.io/hashicorp/aws\\\"]\", shape = \"diamond\"]\n", "                \"[root] var.ami_instance\" [label = \"var.ami_instance\", shape = \"note\"]\n", "                \"[root] var.instance_type\" [label = \"var.instance_type\", shape = \"note\"]\n", "                \"[root] var.region\" [label = \"var.region\", shape = \"note\"]\n", "                \"[root] var.vpc_cidr\" [label = \"var.vpc_cidr\", shape = \"note\"]\n", "                \"[root] var.vpc_subnet_cidr\" [label = \"var.vpc_subnet_cidr\", shape = \"note\"]\n", "                \"[root] aws_subnet.vpc_subnets (expand)\" -> \"[root] aws_vpc.main_vpc (expand)\"\n", "                \"[root] aws_subnet.vpc_subnets (expand)\" -> \"[root] data.aws_availability_zones.aaz (expand)\"\n", "                \"[root] aws_subnet.vpc_subnets (expand)\" -> \"[root] var.vpc_subnet_cidr\"\n", "                \"[root] aws_vpc.main_vpc (expand)\" -> \"[root] provider[\\\"registry.terraform.io/hashicorp/aws\\\"]\"\n", "                \"[root] aws_vpc.main_vpc (expand)\" -> \"[root] var.vpc_cidr\"\n", "                \"[root] data.aws_availability_zones.aaz (expand)\" -> \"[root] provider[\\\"registry.terraform.io/hashicorp/aws\\\"]\"\n", "                \"[root] meta.count-boundary (EachMode fixup)\" -> \"[root] aws_subnet.vpc_subnets (expand)\"\n", "                \"[root] meta.count-boundary (EachMode fixup)\" -> \"[root] output.aazs\"\n", "                \"[root] meta.count-boundary (EachMode fixup)\" -> \"[root] var.ami_instance\"\n", "                \"[root] meta.count-boundary (EachMode fixup)\" -> \"[root] var.instance_type\"\n", "                \"[root] output.aazs\" -> \"[root] data.aws_availability_zones.aaz (expand)\"\n", "                \"[root] provider[\\\"registry.terraform.io/hashicorp/aws\\\"] (close)\" -> \"[root] aws_subnet.vpc_subnets (expand)\"\n", "                \"[root] provider[\\\"registry.terraform.io/hashicorp/aws\\\"]\" -> \"[root] var.region\"\n", "                \"[root] root\" -> \"[root] meta.count-boundary (EachMode fixup)\"\n", "                \"[root] root\" -> \"[root] provider[\\\"registry.terraform.io/hashicorp/aws\\\"] (close)\"\n", "        }\n", "}\n", "```\n"]}, {"cell_type": "markdown", "id": "approved-exclusion", "metadata": {}, "source": ["### 10. Reverting to local state -  Removing the remote_backend\n", "\n", "Now to revert back to using a local terraform.tfstate file:\n", "\n", "Remove the backend definition from your config: ```rm backend.tf```\n", "- or move the backend.tf file or change to another folder\n", "\n", "Then re-init your config: ```terraform init  -migrate-state```\n", "\n", "This will disable the \"S3\" remote_backend\n", "\n", "```\n", "Terraform has detected you're unconfiguring your previously set \"s3\" backend.\n", "Do you want to copy existing state to the new backend?\n", "  Pre-existing state was found while migrating the previous \"s3\" backend to the\n", "  newly configured \"local\" backend. No existing state was found in the newly\n", "  configured \"local\" backend. Do you want to copy this state to the new \"local\"\n", "  backend? Enter \"yes\" to copy and \"no\" to start with an empty state.\n", "\n", "  Enter a value: yes\n", "\n", "\n", "\n", "Successfully unset the backend \"s3\". Terraform will now operate locally.\n", "\n", "Initializing provider plugins...\n", "- Reusing previous version of hashicorp/aws from the dependency lock file\n", "- Installing hashicorp/aws v3.26.0...\n", "- Installed hashicorp/aws v3.26.0 (signed by HashiCorp)\n", "\n", "Terraform has been successfully initialized!\n", "\n", "You may now begin working with Terraform. Try running \"terraform plan\" to see\n", "any changes that are required for your infrastructure. All Terraform commands\n", "should now work.\n", "\n", "If you ever set or change modules or backend configuration for Terraform,\n", "rerun this command to reinitialize your working directory. If you forget, other\n", "commands will detect it and remind you to do so if necessary.\n", "```"]}, {"cell_type": "code", "execution_count": 27, "id": "33147abd", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "Initializing the backend...\n", "Terraform has detected you're unconfiguring your previously set \"s3\" backend.\n", "Acquiring state lock. This may take a few moments...\n", "Do you want to copy existing state to the new backend?\n", "  Pre-existing state was found while migrating the previous \"s3\" backend to the\n", "  newly configured \"local\" backend. No existing state was found in the newly\n", "  configured \"local\" backend. Do you want to copy this state to the new \"local\"\n", "  backend? Enter \"yes\" to copy and \"no\" to start with an empty state.\n", "\n", "  Enter a value: \n", "Releasing state lock. This may take a few moments...\n", "\n", "\n", "Successfully unset the backend \"s3\". Terraform will now operate locally.\n", "\n", "Initializing provider plugins...\n", "- Reusing previous version of hashicorp/aws from the dependency lock file\n", "- Using previously-installed hashicorp/aws v4.49.0\n", "\n", "Terraform has been successfully initialized!\n", "\n", "You may now begin working with Terraform. Try running \"terraform plan\" to see\n", "any changes that are required for your infrastructure. All Terraform commands\n", "should now work.\n", "\n", "If you ever set or change modules or backend configuration for Terraform,\n", "rerun this command to reinitialize your working directory. If you forget, other\n", "commands will detect it and remind you to do so if necessary.\n", "-rw-rw-r-- 1 student student 6445 Jan  9 18:49 terraform.tfstate\n"]}], "source": ["rm backend.tf\n", "\n", "echo yes | terraform init  -migrate-state\n", "\n", "# Then perform ```terraform init --backend=false```\n", "\n", "ls -al terraform.tfstate"]}, {"cell_type": "markdown", "id": "8617377d", "metadata": {}, "source": ["\n", "### In case of errors\n", "\n", "If you hit errors reverting to a local state, perform the following steps:\n", "\n", "**Note:** This assumes that you have TF_DATA_DIR exported as ~/dot.terraform\n", "\n", "```\n", "mv ~/dot.terraform/terraform.tfstate ~/dot.terraform/terraform.tfstate.remote.backup\n", "\n", "terraform init\n", "```"]}, {"cell_type": "code", "execution_count": 29, "id": "constant-journey", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["aws_dynamodb_table.terraform_locks\n", "aws_s3_bucket.remote_state\n", "aws_s3_bucket.test_bucket\n"]}], "source": ["terraform state list"]}, {"cell_type": "markdown", "id": "biblical-hybrid", "metadata": {}, "source": ["### 10. Cleanup"]}, {"cell_type": "markdown", "id": "completed-costa", "metadata": {}, "source": ["Now destroy the formerly created AWS S3 bucket and dynamoDB table"]}, {"cell_type": "code", "execution_count": 30, "id": "understood-convertible", "metadata": {"scrolled": false}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["aws_dynamodb_table.terraform_locks: Refreshing state... [id=dynamodb-lock]\n", "aws_s3_bucket.test_bucket: Refreshing state... [id=20230109-mjbrightctest]\n", "aws_s3_bucket.remote_state: Refreshing state... [id=20230109-mjbrightc]\n", "\n", "Terraform used the selected providers to generate the following execution plan.\n", "Resource actions are indicated with the following symbols:\n", "  - destroy\n", "\n", "Terraform will perform the following actions:\n", "\n", "  # aws_dynamodb_table.terraform_locks will be destroyed\n", "  - resource \"aws_dynamodb_table\" \"terraform_locks\" {\n", "      - arn            = \"arn:aws:dynamodb:us-west-1:816376574968:table/dynamodb-lock\" \u001b[90m-> \u001b[90mnull\n", "      - billing_mode   = \"PROVISIONED\" \u001b[90m-> \u001b[90mnull\n", "      - hash_key       = \"LockID\" \u001b[90m-> \u001b[90mnull\n", "      - id             = \"dynamodb-lock\" \u001b[90m-> \u001b[90mnull\n", "      - name           = \"dynamodb-lock\" \u001b[90m-> \u001b[90mnull\n", "      - read_capacity  = 1 \u001b[90m-> \u001b[90mnull\n", "      - stream_enabled = false \u001b[90m-> \u001b[90mnull\n", "      - tags           = {\n", "          - \"LabName\" = \"6.StoringPersistentStates\"\n", "        } \u001b[90m-> \u001b[90mnull\n", "      - tags_all       = {\n", "          - \"LabName\" = \"6.StoringPersistentStates\"\n", "        } \u001b[90m-> \u001b[90mnull\n", "      - write_capacity = 1 \u001b[90m-> \u001b[90mnull\n", "\n", "      - attribute {\n", "          - name = \"LockID\" \u001b[90m-> \u001b[90mnull\n", "          - type = \"S\" \u001b[90m-> \u001b[90mnull\n", "        }\n", "\n", "      - point_in_time_recovery {\n", "          - enabled = false \u001b[90m-> \u001b[90mnull\n", "        }\n", "\n", "      - ttl {\n", "          - enabled = false \u001b[90m-> \u001b[90mnull\n", "        }\n", "    }\n", "\n", "  # aws_s3_bucket.remote_state will be destroyed\n", "  - resource \"aws_s3_bucket\" \"remote_state\" {\n", "      - arn                         = \"arn:aws:s3:::20230109-mjbrightc\" \u001b[90m-> \u001b[90mnull\n", "      - bucket                      = \"20230109-mjbrightc\" \u001b[90m-> \u001b[90mnull\n", "      - bucket_domain_name          = \"20230109-mjbrightc.s3.amazonaws.com\" \u001b[90m-> \u001b[90mnull\n", "      - bucket_regional_domain_name = \"20230109-mjbrightc.s3.us-west-1.amazonaws.com\" \u001b[90m-> \u001b[90mnull\n", "      - force_destroy               = true \u001b[90m-> \u001b[90mnull\n", "      - hosted_zone_id              = \"Z2F56UZL2M1ACD\" \u001b[90m-> \u001b[90mnull\n", "      - id                          = \"20230109-mjbrightc\" \u001b[90m-> \u001b[90mnull\n", "      - object_lock_enabled         = false \u001b[90m-> \u001b[90mnull\n", "      - region                      = \"us-west-1\" \u001b[90m-> \u001b[90mnull\n", "      - request_payer               = \"BucketOwner\" \u001b[90m-> \u001b[90mnull\n", "      - tags                        = {\n", "          - \"LabName\" = \"6.StoringPersistentStates\"\n", "        } \u001b[90m-> \u001b[90mnull\n", "      - tags_all                    = {\n", "          - \"LabName\" = \"6.StoringPersistentStates\"\n", "        } \u001b[90m-> \u001b[90mnull\n", "\n", "      - grant {\n", "          - id          = \"968fa2d82a42737a0bed914a047f15154b89bf1bcc8c50a320a36a56c60f1ad1\" \u001b[90m-> \u001b[90mnull\n", "          - permissions = [\n", "              - \"FULL_CONTROL\",\n", "            ] \u001b[90m-> \u001b[90mnull\n", "          - type        = \"CanonicalUser\" \u001b[90m-> \u001b[90mnull\n", "        }\n", "\n", "      - versioning {\n", "          - enabled    = false \u001b[90m-> \u001b[90mnull\n", "          - mfa_delete = false \u001b[90m-> \u001b[90mnull\n", "        }\n", "    }\n", "\n", "  # aws_s3_bucket.test_bucket will be destroyed\n", "  - resource \"aws_s3_bucket\" \"test_bucket\" {\n", "      - arn                         = \"arn:aws:s3:::20230109-mjbrightctest\" \u001b[90m-> \u001b[90mnull\n", "      - bucket                      = \"20230109-mjbrightctest\" \u001b[90m-> \u001b[90mnull\n", "      - bucket_domain_name          = \"20230109-mjbrightctest.s3.amazonaws.com\" \u001b[90m-> \u001b[90mnull\n", "      - bucket_regional_domain_name = \"20230109-mjbrightctest.s3.us-west-1.amazonaws.com\" \u001b[90m-> \u001b[90mnull\n", "      - force_destroy               = true \u001b[90m-> \u001b[90mnull\n", "      - hosted_zone_id              = \"Z2F56UZL2M1ACD\" \u001b[90m-> \u001b[90mnull\n", "      - id                          = \"20230109-mjbrightctest\" \u001b[90m-> \u001b[90mnull\n", "      - object_lock_enabled         = false \u001b[90m-> \u001b[90mnull\n", "      - region                      = \"us-west-1\" \u001b[90m-> \u001b[90mnull\n", "      - request_payer               = \"BucketOwner\" \u001b[90m-> \u001b[90mnull\n", "      - tags                        = {\n", "          - \"LabName\" = \"6.StoringPersistentStates\"\n", "        } \u001b[90m-> \u001b[90mnull\n", "      - tags_all                    = {\n", "          - \"LabName\" = \"6.StoringPersistentStates\"\n", "        } \u001b[90m-> \u001b[90mnull\n", "\n", "      - grant {\n", "          - id          = \"968fa2d82a42737a0bed914a047f15154b89bf1bcc8c50a320a36a56c60f1ad1\" \u001b[90m-> \u001b[90mnull\n", "          - permissions = [\n", "              - \"FULL_CONTROL\",\n", "            ] \u001b[90m-> \u001b[90mnull\n", "          - type        = \"CanonicalUser\" \u001b[90m-> \u001b[90mnull\n", "        }\n", "\n", "      - versioning {\n", "          - enabled    = false \u001b[90m-> \u001b[90mnull\n", "          - mfa_delete = false \u001b[90m-> \u001b[90mnull\n", "        }\n", "    }\n", "\n", "Plan: 0 to add, 0 to change, 3 to destroy.\n", "aws_s3_bucket.test_bucket: Destroying... [id=20230109-mjbrightctest]\n", "aws_dynamodb_table.terraform_locks: Destroying... [id=dynamodb-lock]\n", "aws_s3_bucket.remote_state: Destroying... [id=20230109-mjbrightc]\n", "aws_s3_bucket.test_bucket: Destruction complete after 0s\n", "aws_s3_bucket.remote_state: Destruction complete after 2s\n", "aws_dynamodb_table.terraform_locks: Destruction complete after 4s\n", "\n", "Destroy complete! Resources: 3 destroyed.\n", "\n"]}], "source": ["terraform destroy "]}, {"cell_type": "code", "execution_count": 31, "id": "graduate-survival", "metadata": {}, "outputs": [], "source": ["terraform state list"]}, {"cell_type": "code", "execution_count": 32, "id": "665ff51d", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["2023-Jan-09:[TF-1.3.7] Lab updated on node tf[terraform 1.3.7]\n"]}, {"ename": "", "evalue": "1", "output_type": "error", "traceback": []}], "source": [""]}, {"cell_type": "markdown", "id": "universal-gilbert", "metadata": {}, "source": ["<hr/>\n", "\n", "<!-- Why does this no longer work ??\n", "<img src=\"../../../static/images/ThickBlueBar.png\" />\n", "<img src=\"../../../static/images/LOGO.jpg\" width=200 />\n", "-->\n", "\n", "<img src=\"../images/ThickBlueBar.png\" />\n", "<img src=\"../images/LOGO.jpg\" width=200 />"]}], "metadata": {"kernelspec": {"display_name": "Bash", "language": "bash", "name": "bash"}, "language_info": {"codemirror_mode": "shell", "file_extension": ".sh", "mimetype": "text/x-sh", "name": "bash"}}, "nbformat": 4, "nbformat_minor": 5}